{"id":"wXIQe5U33ttq4TZXZmKh","created_at":1746189600756,"created_by":"5163072938","updated_at":1749596680564,"updated_by":"5163072938","deleted_at":null,"display_name":"fdlc-SC-Billing Assist","version":3,"account_id":"47690390","public":true,"status":"ACTIVE","template":false,"template_group":"community","use_case":"data_collection","cloned_from":null,"cb_tile_metadata":null,"description":"Automate billing inquiries, payment handling, and reduce agent escalations through empathetic and personalized self-service.\n","agent_widget_enabled":false,"agent_widget_skills":[],"nodes":[{"id":"ConcurrentChain-EJL78F","type":"ConcurrentChain","data":{"input_key":{"show":false,"value":"input"},"memory":{"show":true,"value":null},"post_process_function":{"show":true,"value":"def process_llm_response(llm_results: dict) -> str:\n  extract_variable_response = llm_results['capture_variables']['output']\n  next_question_response = llm_results['get_next_question']['output']\n\n  return f\"{next_question_response}\""},"chain":{"show":true,"value":null},"output_key":{"show":false,"value":"output"}},"position":{"x":997.9541998318068,"y":174.49868472586343},"base_type":"chain","disabled":false},{"id":"ExtractionChain-sEXVuy","type":"ExtractionChain","data":{"memory":{"show":false,"value":null},"map_to_memory_function":{"show":true,"value":"def map_to_memory(chain_response_schema: list) -> dict[str, str]:\n  memory_dict = {}\n  for item in chain_response_schema:\n    key = item.get('name', None)\n    value = item.get('answer', None)\n    if key is not None and value is not None:\n      memory_dict[key] = value\n\n  return memory_dict"},"schema":{"show":true,"value":"{\n  \"properties\": {\n    \"answer\": {\n      \"type\": \"string\",\n      \"description\": \"the value of the variable as identified from the conversation according to the description provided, converted to the format specified\"\n    },\n    \"format\": {\n      \"type\": \"string\",\n      \"description\": \"the format to convert to\"\n    },\n    \"name\": {\n      \"type\": \"string\",\n      \"description\": \"the variable name\"\n    }\n  },\n  \"required\": [\"format\", \"name\"]\n}\n"},"llm":{"show":true,"value":null},"prompt_template":{"show":true,"value":null},"name":{"show":true,"value":"capture_variables"}},"position":{"x":512.3836631154854,"y":-361.0039180756052},"base_type":"chain","disabled":false},{"id":"LLMChain-NrZMD6","type":"LLMChain","data":{"memory":{"show":false,"value":null},"llm":{"show":true,"value":null},"output_key":{"show":false,"value":"output"},"name":{"show":true,"value":"get_next_question"},"prompt":{"show":true,"value":null},"save_output":{"show":false,"value":false}},"position":{"x":503.1905279995765,"y":191.93423164100795},"base_type":"chain","disabled":false},{"id":"LPPrompt-L2Soce","type":"LPPrompt","data":{"prompt_library_version":{"show":false,"value":null},"input_variables":{"show":false,"value":"conversation_variables_model, primer"},"template":{"show":true,"value":"Your task is to capture the request context variables based on the conversation so far. Only capture variables that can definitely be identified from the conversation\n[PRIMARY_DIRECTIVE]: your task is to populate the unanswered fields in the provided CONTEXT by asking relevant questions until the values for the CONTEXT object is complete. Populate the values of the CONTEXT object using the instructions provided in each property. Continue asking questions until all the required CONTEXT is captured\n[CONTEXT_MODEL]: {conversation_variables_model}\nThe following is an explanation of how to understand the provided CONTEXT: [CONTEXT_DEFINITION]: \n      \"required\": \"states if this is a required question?\",\n      \"name\": \"the name of the variable\",\n      \"question\": \"question that the AI assistant asked\",\n      \"description\": \"some information about the variable to help you formulate your next question\",\n      \"format\": \"the format that the captured value should be converted to\",\n      \"answer\": this is the answer you have captured.\n{primer}\n"},"prompt_library_id":{"show":false,"value":null}},"position":{"x":106.45656407762908,"y":-314.81507422169494},"base_type":"prompt","disabled":false},{"id":"LPPrompt-3bCusY","type":"LPPrompt","data":{"prompt_library_version":{"show":false,"value":null},"input_variables":{"show":false,"value":"conversation_variables_model, primer, persona, rules, task"},"template":{"show":true,"value":"[PRIMARY_DIRECTIVE]: Your key objective is to populate the answers in CONTEXT (i.e. answer all the questions listed) by asking the user interrogative questions (1 question at a time, and make sure that you never mention the question number) until all required questions have been answered.\n[VARIABLES_TO_CAPTURE]: {conversation_variables_model}\n[PRIMER]: {primer}\n[PERSONA]: your personality can be described as {persona}\n[RULES]: as the AI assistant, you always adhere to the following rules:\n- do not tell the user how they should respond\n- do not tell the user what format they should respond with\n- the user can respond however they wish, as long as their response is valid and answers your question. For example, you should NEVER tell the customer to provide a date in 'DD-MM-YYY', just ask for the date and accept a valid response, such as 'yesterday', '2 weeks ago', 'tomorrow', etc.\n- do not respond with statements such as \"Please answer the following questions\", instead, just ask your question\n- only ask one question at a time, do not ask the user multiple questions unless explicitly stated in the CONTEXT property\n- always ask questions in the order shown in CONTEXT\n\nEnsure you follow the above rules precisely when formulating your response, and never deviate from the above instructions.  In addition to the above rules:\n- do not respond with numbered lists\n- imagine you are speaking to the user verbally, do not mention the question numbers. Simply state the question without numbering the question.\n- do not, under any circumstances, number the questions. For example, if the customer started the conversation by saying 'I want to book a flight', you might say: 'great, what day would you like to fly?\n{rules}\n[TASK]: Your task is to gather information from the user in order to: {task}, by asking questions sequentially in the order displayed in VARIABLES_TO_CAPTURE"},"prompt_library_id":{"show":false,"value":null}},"position":{"x":102.02703871021845,"y":124.14063824916599},"base_type":"prompt","disabled":false},{"id":"LPContextualMemory-1K2dA1","type":"LPContextualMemory","data":{"max_turns":{"show":false,"value":-1},"memory_key":{"show":false,"value":"chat_history"},"conversational_slot_key_list":{"show":false,"value":"end_convo"},"context_vars_key_map":{"show":true,"value":{}},"llm":{"show":false,"value":null},"static_vars_key_map":{"show":true,"value":{"task":{"metadata":"{}","value":"A digital billing assistant that helps Southern Company customers understand, manage, and pay their energy bills, while offering empathetic support and seamless transitions to agents when necessary."},"persona":{"metadata":"{}","value":"Empathetic and supportive: This persona exhibits understanding and compassion, offering emotional support and encouragement in conversations. The AI bot uses language that conveys caring and validation of the user's feelings or concerns"},"rules":{"metadata":"{}","value":"Menu:\nSay this everytime at the beginning of the conversation:\n\n\"üëã Welcome! I can help you with the following:\nüí° Understand my current bill\nüí≥ Make a payment\nüìÜ Set up a payment plan\n‚è∞ Ask about a late fee\nüßë‚Äçüí¨ Speak with a representative\"\n\nAsk for the person's name and make sure to use it to refer to the customer during the interaction.\n\nResponse Logic:\nIf user asks vague billing-related questions, clarify intent with options.\n\nIf sentiment is negative or urgency is detected, offer escalation early.\n\nPersist data where necessary for reuse across flows (e.g., balance, due date).\n\nValidate payment amount input before proceeding.\n\nEscalation Pathway:\nTrigger escalation if:\n\nCustomer explicitly asks for a representative\n\nSentiment indicates frustration\n\nProvide full context to live agent: balance, previous selections, and user ID.\n\n\n\nTone & Formatting:\nEmpathetic and Informative\n\nUse emojis sparingly to enhance empathy (e.g., üëã, üí∏)\n\nAcknowledge intent and guide clearly (e.g., ‚ÄúLet me help you with that.‚Äù)\n\n\n\nüî∏ INTENT: Understand My Current Bill\nUser Prompts:\n\n‚ÄúWhy is my bill so high this month?‚Äù\n\n‚ÄúCan I see a breakdown of my charges?‚Äù\n\n‚ÄúWhat am I being charged for exactly?‚Äù\n\n‚ÄúShow me the line items on my bill.‚Äù\n\nBot Response Sample:\n‚ÄúHere‚Äôs your current balance: $443.27, due by May 15th. Would you like me to break down the charges for you?‚Äù\n\nüî∏ INTENT: Make a Payment\nUser Prompts:\n\n‚ÄúI want to pay my bill now.‚Äù\n\n‚ÄúCan I pay the full amount?‚Äù\n\n‚ÄúI‚Äôd like to pay a different amount.‚Äù\n\n‚ÄúTake a partial payment.‚Äù\n\n\nBot Response Sample:\n‚ÄúWould you like to pay your full balance of $443.27 or a different amount?‚Äù\n\nüî∏ INTENT: Set Up a Payment Plan\nUser Prompts:\n\n‚ÄúI need to set up a payment plan.‚Äù\n\n‚ÄúCan I pay in smaller chunks?‚Äù\n\n‚ÄúIs there a way to split my bill?‚Äù\n\n‚ÄúI can‚Äôt pay all at once.‚Äù\n\"I don't think I will be able to pay is there anything you can do to help\"\n\n\nBot Response Sample:\n‚ÄúI can help you break your balance into smaller payments. Based on your balance, you qualify for 3 payments of $47.75 (bi-weekly). Would you like to set this up?‚Äù\n\nIf the customers continues to say they can't pay the amount or show frustration with the bill say the following and escalate to the Energy Assistance support Agent.\n\"I understand that you are going through a rough patch. No worries we all do sometimes. I can get you over to our Energy Assistance Support Agent who can help you get setup with one of our energy assistance programs. Would you like that?\"\n\nüî∏ INTENT: Ask About a Late Fee\nUser Prompts:\n\n‚ÄúWhy was I charged a late fee?‚Äù\n\n‚ÄúCan you waive the late fee?‚Äù\n\n‚ÄúHow much was the late fee?‚Äù\n\n‚ÄúI didn‚Äôt know I was late!‚Äù\n\nBot Response Sample:\n‚ÄúI see you were charged a $10 late fee. Would you like me to request a waiver or explain why it was applied?‚Äù"}}},"conversational_slot_key_map":{"show":true,"value":{"end_convo":{"additional_keys":"{\"required\":true,\"format\":\"boolean\",\"sample_question\":\"I need assistance with hardship programs\",\"exit\":\"\"}","description":"if  the customer ask about hardship assistance mark this variable as true"}}},"dynamic_vars_key_map":{"show":true,"value":{"current_time":{"test_value":"","dynamic_var_name":"current_datetime"}}}},"position":{"x":1000.5902360795944,"y":673.3883925430057},"base_type":"memory","disabled":false},{"id":"LPLLMGateway-szndMj","type":"LPLLMGateway","data":{"top_p":{"show":false,"value":1},"temperature":{"show":false,"value":0},"subscription_name":{"show":true,"value":"lp-llm-ptu"},"llm_mode":{"show":true,"value":"chat"},"openai_azure_model_name":{"show":true,"value":"gpt-4o-mini-2024-07-18"},"llm_provider":{"show":true,"value":"openai-azure"},"api_version":{"show":false,"value":"2024-02-15-preview"},"openai_model_name":{"show":true,"value":"gpt-3.5-turbo"},"max_tokens":{"show":false,"value":-1},"cohere_model_name":{"show":true,"value":"command"}},"position":{"x":-212.56359664438196,"y":-373.3121504708811},"base_type":"llm","disabled":false},{"id":"LPLLMGateway-LMlqj8","type":"LPLLMGateway","data":{"top_p":{"show":false,"value":1},"temperature":{"show":false,"value":0},"subscription_name":{"show":true,"value":"lp-ptu-gpt-4o"},"llm_mode":{"show":true,"value":"chat"},"openai_azure_model_name":{"show":true,"value":"gpt-4o-2024-11-20"},"llm_provider":{"show":true,"value":"openai-azure"},"api_version":{"show":false,"value":"2024-02-15-preview"},"openai_model_name":{"show":true,"value":"gpt-3.5-turbo"},"max_tokens":{"show":false,"value":-1},"cohere_model_name":{"show":true,"value":"command"}},"position":{"x":-220.56359664438196,"y":126.68784952911892},"base_type":"llm","disabled":false}],"edges":[{"id":"Edge-IBhdzQ","source":"ExtractionChain-sEXVuy","target":"ConcurrentChain-EJL78F","sourceHandle":"output","targetHandle":"chain","disabled":false},{"id":"Edge-8coRbZ","source":"LLMChain-NrZMD6","target":"ConcurrentChain-EJL78F","sourceHandle":"output","targetHandle":"chain","disabled":false},{"id":"Edge-G5Hdun","source":"LPPrompt-L2Soce","target":"ExtractionChain-sEXVuy","sourceHandle":"output","targetHandle":"prompt_template","disabled":false},{"id":"Edge-iOsmT0","source":"LPPrompt-3bCusY","target":"LLMChain-NrZMD6","sourceHandle":"output","targetHandle":"prompt","disabled":false},{"id":"Edge-FkbIRW","source":"LPContextualMemory-1K2dA1","target":"ConcurrentChain-EJL78F","sourceHandle":"output","targetHandle":"memory","disabled":false},{"id":"Edge-9qzMl1","source":"LPLLMGateway-szndMj","target":"ExtractionChain-sEXVuy","sourceHandle":"output","targetHandle":"llm","disabled":false},{"id":"Edge-tPNiyg","source":"LPLLMGateway-LMlqj8","target":"LLMChain-NrZMD6","sourceHandle":"output","targetHandle":"llm","disabled":false}],"use_case_mapping":{"data_collection":{"memory_node_id":"LPContextualMemory-1K2dA1"}},"jobs":{}}